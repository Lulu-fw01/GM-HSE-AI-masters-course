{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NickKar30/GM-HSE-AI-masters-course/blob/main/Hometasks/Base/GenDL_HT1_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ2DRg1TS_np"
      },
      "source": [
        "# Домашнее задание - 1 (базовая группа)\n",
        "\n",
        "В этом домашнем задании вы потренируетесь решать задачу speech-to-text.\n",
        "\n",
        "Вы не будете тренировать сложную архитектуру с нуля, а попробуете решить эту задачу, пройдя по пайплайну, в котором задача разбита на несколько простых шагов.\n",
        "\n",
        "- В этом задании мы призываем вас по-максимуму использовать документацию моделей и получить опыт написания кода без заготовок"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p9lL-VPdDCo"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "LHP5e6rrEXzd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        }
      ],
      "source": [
        "!pip install evaluate -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJTV1KLsgF99"
      },
      "source": [
        "## Шаг 1 (1 балл)\n",
        "\n",
        "* Возьмите датасет https://disk.yandex.ru/d/v2Hipv7XG4fEDQ, содержащий русскоязычные аудиозаписи\n",
        "\n",
        "* Примените модель [whisper-small](https://huggingface.co/openai/whisper-small) из HF для определения сказанного в аудио.\n",
        "\n",
        "* Выведите результат работы модели для 10 случайных аудио из датасета\n",
        "\n",
        "Не стесняйтесь пользоваться документацией и источниками знаний из интернета!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "urls = []\n",
        "with open('urls_normalized.tsv', 'r') as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        urls.append(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchaudio\n",
        "from transformers import WhisperForConditionalGeneration, WhisperProcessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting librosa\n",
            "  Using cached librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting soundfile\n",
            "  Downloading soundfile-0.13.1-py2.py3-none-macosx_11_0_arm64.whl.metadata (16 kB)\n",
            "Collecting audioread>=2.1.9 (from librosa)\n",
            "  Using cached audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting numba>=0.51.0 (from librosa)\n",
            "  Downloading numba-0.62.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /Users/lumarkov/git/luka/GM-HSE-AI-masters-course/ml_env_py311/lib/python3.11/site-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /Users/lumarkov/git/luka/GM-HSE-AI-masters-course/ml_env_py311/lib/python3.11/site-packages (from librosa) (1.16.2)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /Users/lumarkov/git/luka/GM-HSE-AI-masters-course/ml_env_py311/lib/python3.11/site-packages (from librosa) (1.7.2)\n",
            "Requirement already satisfied: joblib>=1.0 in /Users/lumarkov/git/luka/GM-HSE-AI-masters-course/ml_env_py311/lib/python3.11/site-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /Users/lumarkov/git/luka/GM-HSE-AI-masters-course/ml_env_py311/lib/python3.11/site-packages (from librosa) (5.2.1)\n",
            "Collecting pooch>=1.1 (from librosa)\n",
            "  Using cached pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting soxr>=0.3.2 (from librosa)\n",
            "  Downloading soxr-1.0.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /Users/lumarkov/git/luka/GM-HSE-AI-masters-course/ml_env_py311/lib/python3.11/site-packages (from librosa) (4.15.0)\n",
            "Collecting lazy_loader>=0.1 (from librosa)\n",
            "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting msgpack>=1.0 (from librosa)\n",
            "  Downloading msgpack-1.1.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: cffi>=1.0 in /Users/lumarkov/git/luka/GM-HSE-AI-masters-course/ml_env_py311/lib/python3.11/site-packages (from soundfile) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /Users/lumarkov/git/luka/GM-HSE-AI-masters-course/ml_env_py311/lib/python3.11/site-packages (from cffi>=1.0->soundfile) (2.23)\n",
            "Requirement already satisfied: packaging in /Users/lumarkov/git/luka/GM-HSE-AI-masters-course/ml_env_py311/lib/python3.11/site-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
            "Collecting llvmlite<0.46,>=0.45.0dev0 (from numba>=0.51.0->librosa)\n",
            "  Downloading llvmlite-0.45.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /Users/lumarkov/git/luka/GM-HSE-AI-masters-course/ml_env_py311/lib/python3.11/site-packages (from pooch>=1.1->librosa) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /Users/lumarkov/git/luka/GM-HSE-AI-masters-course/ml_env_py311/lib/python3.11/site-packages (from pooch>=1.1->librosa) (2.32.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/lumarkov/git/luka/GM-HSE-AI-masters-course/ml_env_py311/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/lumarkov/git/luka/GM-HSE-AI-masters-course/ml_env_py311/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/lumarkov/git/luka/GM-HSE-AI-masters-course/ml_env_py311/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/lumarkov/git/luka/GM-HSE-AI-masters-course/ml_env_py311/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.10.5)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/lumarkov/git/luka/GM-HSE-AI-masters-course/ml_env_py311/lib/python3.11/site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Using cached librosa-0.11.0-py3-none-any.whl (260 kB)\n",
            "Downloading soundfile-0.13.1-py2.py3-none-macosx_11_0_arm64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached audioread-3.0.1-py3-none-any.whl (23 kB)\n",
            "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
            "Downloading msgpack-1.1.2-cp311-cp311-macosx_11_0_arm64.whl (84 kB)\n",
            "Downloading numba-0.62.1-cp311-cp311-macosx_11_0_arm64.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading llvmlite-0.45.1-cp311-cp311-macosx_11_0_arm64.whl (37.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hUsing cached pooch-1.8.2-py3-none-any.whl (64 kB)\n",
            "Downloading soxr-1.0.0-cp311-cp311-macosx_11_0_arm64.whl (165 kB)\n",
            "Installing collected packages: soxr, msgpack, llvmlite, lazy_loader, audioread, soundfile, pooch, numba, librosa\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9/9\u001b[0m [librosa]m7/9\u001b[0m [numba]te]\n",
            "\u001b[1A\u001b[2KSuccessfully installed audioread-3.0.1 lazy_loader-0.4 librosa-0.11.0 llvmlite-0.45.1 msgpack-1.1.2 numba-0.62.1 pooch-1.8.2 soundfile-0.13.1 soxr-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install librosa soundfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "\n",
        "def recognize_audio(processor: WhisperProcessor, model_w: WhisperForConditionalGeneration, url: str):\n",
        "    response = requests.get(url, timeout=30)\n",
        "    response.raise_for_status()\n",
        "        \n",
        "    temp_filename = f\"temp_audio_{hash(url)}.wav\"\n",
        "    with open(temp_filename, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "        \n",
        "    wav, sr = librosa.load(temp_filename, sr=16000)\n",
        "    wav = torch.from_numpy(wav).unsqueeze(0)\n",
        "    if wav.shape[0] > 1:\n",
        "        wav = wav.mean(dim=0, keepdim=True)\n",
        "\n",
        "    if os.path.exists(temp_filename):\n",
        "        os.remove(temp_filename)\n",
        "                \n",
        "    input_features = processor(wav.squeeze().numpy(), sampling_rate=sr, return_tensors=\"pt\").input_features\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generated_ids = model_w.generate(\n",
        "            input_features,\n",
        "            max_length=448,\n",
        "            language=\"russian\",\n",
        "            task=\"transcribe\"\n",
        "        )\n",
        "        \n",
        "    return processor.batch_decode(generated_ids, skip_special_tokens=True)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "GBIYfUYn0Ds5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Audio 1 (URL: http://storage.mds.yandex.net:80/get-voicetoloka/2021744/4201a552-ca79-4a67-9b2a-126d75d0a3be):\n",
            "Detected text:  Римский каникул\n",
            "--------------------------------------------------\n",
            "Audio 2 (URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/759edbe2-5d4f-4c88-acdc-439fcd5eb6c1):\n",
            "Detected text:  Michael Fradey\n",
            "--------------------------------------------------\n",
            "Audio 3 (URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/47b9b402-e832-438d-ad85-3f7375867e4a):\n",
            "Detected text:  КОУ ПОРТЕР\n",
            "--------------------------------------------------\n",
            "Audio 4 (URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/197f271b-b23f-4ee0-b240-e956a172d7af):\n",
            "Detected text:  Жизнь других.\n",
            "--------------------------------------------------\n",
            "Audio 5 (URL: http://storage.mds.yandex.net:80/get-voicetoloka/1879367/163e0da8-750f-45d4-b5d5-8982fb060c12):\n",
            "Detected text:  Новый кинотеатр пародизо\n",
            "--------------------------------------------------\n",
            "Audio 6 (URL: http://storage.mds.yandex.net:80/get-voicetoloka/1879367/c5a115d7-015f-421c-94ce-ed9928151491):\n",
            "Detected text:  Аристотель.\n",
            "--------------------------------------------------\n",
            "Audio 7 (URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/25c34061-fef9-4563-a813-e36b910f1e70):\n",
            "Detected text:  Рене-декарт.\n",
            "--------------------------------------------------\n",
            "Audio 8 (URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/84c7ed3f-4010-4de2-8a30-88a312be0bba):\n",
            "Detected text:  Смоки Робинсон\n",
            "--------------------------------------------------\n",
            "Audio 9 (URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/776a335c-4817-4ed4-8a63-4b88bfaf1c2d):\n",
            "Detected text:  Мой сосед татура.\n",
            "--------------------------------------------------\n",
            "Audio 10 (URL: http://storage.mds.yandex.net:80/get-voicetoloka/1879367/08890a89-c3df-4e4a-b4ac-169a347791cc):\n",
            "Detected text:  Бабель Исаак, Эммануи Лавич.\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import random\n",
        "import os\n",
        "import librosa\n",
        "\n",
        "## https://huggingface.co/openai/whisper-small\n",
        "WHISPER_MODEL_NAME = \"openai/whisper-small\"\n",
        "processor = WhisperProcessor.from_pretrained(WHISPER_MODEL_NAME)\n",
        "model = WhisperForConditionalGeneration.from_pretrained(WHISPER_MODEL_NAME)\n",
        "\n",
        "rnd_urls = random.sample(urls, 10)\n",
        "\n",
        "texts = []\n",
        "for i, url in enumerate(rnd_urls, 1):\n",
        "        transcription = recognize_audio(processor, model, url)\n",
        "        print(f\"Audio {i} (URL: {url}):\")\n",
        "        print(f\"Detected text: {transcription}\")\n",
        "        print(\"-\" * 50)\n",
        "        texts.append(transcription)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rrbQapLh7w5"
      },
      "source": [
        "## Шаг 2 (1 балл)\n",
        "\n",
        "Текст распознается с ошибками.\n",
        "Попробуйте исправить ошибки с помощью готовой (предобученной) модели spell correction.\n",
        "\n",
        "Выведите на экран 10 текстов с предыдущего шага и их исправления с помощью модели https://huggingface.co/UrukHan/t5-russian-spell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "MAX_LENGTH = 256\n",
        "\n",
        "def correct_text(model, tokenizer, text):\n",
        "    inputs = tokenizer(\n",
        "        text, \n",
        "        return_tensors=\"pt\", \n",
        "        max_length=MAX_LENGTH, \n",
        "        truncation=True,\n",
        "        padding=True\n",
        "    )\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            inputs.input_ids,\n",
        "            max_length=MAX_LENGTH,\n",
        "            num_beams=4,\n",
        "            early_stopping=True,\n",
        "            do_sample=False\n",
        "        )\n",
        "    corrected_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return corrected_text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "6EJIcfzWL7Ox"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text 1:\n",
            "Original:  Римский каникул\n",
            "Fixed: Римский каникул.\n",
            "--------------------------------------------------\n",
            "text 2:\n",
            "Original:  Michael Fradey\n",
            "Fixed: Michael Fradey\n",
            "--------------------------------------------------\n",
            "text 3:\n",
            "Original:  КОУ ПОРТЕР\n",
            "Fixed: КОМУ ПОРТЕРТЕР\n",
            "--------------------------------------------------\n",
            "text 4:\n",
            "Original:  Жизнь других.\n",
            "Fixed: Жизнь других\n",
            "--------------------------------------------------\n",
            "text 5:\n",
            "Original:  Новый кинотеатр пародизо\n",
            "Fixed: Новый кинотеатр пародии\n",
            "--------------------------------------------------\n",
            "text 6:\n",
            "Original:  Аристотель.\n",
            "Fixed: Аристотель\n",
            "--------------------------------------------------\n",
            "text 7:\n",
            "Original:  Рене-декарт.\n",
            "Fixed: Рене-Декарт\n",
            "--------------------------------------------------\n",
            "text 8:\n",
            "Original:  Смоки Робинсон\n",
            "Fixed: Смоки Робинсон\n",
            "--------------------------------------------------\n",
            "text 9:\n",
            "Original:  Мой сосед татура.\n",
            "Fixed: Мой сосед Татура.\n",
            "--------------------------------------------------\n",
            "text 10:\n",
            "Original:  Бабель Исаак, Эммануи Лавич.\n",
            "Fixed: Бабель Исаак Исаак и Эммануил Лавич\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "T5_MODEL_NAME = 'UrukHan/t5-russian-spell'\n",
        "\n",
        "spell_tokenizer = AutoTokenizer.from_pretrained(T5_MODEL_NAME)\n",
        "spell_model = AutoModelForSeq2SeqLM.from_pretrained(T5_MODEL_NAME)\n",
        "\n",
        "for i, original_text in enumerate(texts, 1):\n",
        "    print(f\"text {i}:\")\n",
        "    print(f\"Original: {original_text}\")\n",
        "    print(f\"Fixed: {correct_text(spell_model, spell_tokenizer, original_text)}\")\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpXtmy6GiDk3"
      },
      "source": [
        "## Шаг 3 (2 балла)\n",
        "\n",
        "Соберите данные для дообучения модели выше. Для дообучения мы предлагаем вам использовать бесплатный api Groq: https://console.groq.com/docs/quickstart\n",
        "\n",
        "Разберитесь с тем как пользоваться api (мы немного поможем вам с этим кодом ниже) и с его помощью соберите датасет (можно в несколько запросов).\n",
        "\n",
        "- **0.5 балла** ставится за сбор датасета размером >1000 строк и сохранение в локальный файл/файлы\n",
        "\n",
        "- **еще 0.5 балла** ставится за [создание huggingface dataset](https://huggingface.co/docs/datasets/create_dataset) (через использование библиотек datasets и huggingface) и [сохранение собранного датасета напрямую в HuggingFace](https://huggingface.co/docs/datasets/upload_dataset)\n",
        "\n",
        "- **еще 1 балл** ставится за сбор датасета размером >1000 строк, на котором путем дообучения получится увеличить качество исправления опечаток в поставленной задаче (см. шаг 6) по сравнению с качеством прогноза той же, но предобученной модели\n",
        "\n",
        "P.S. Если у Вас нет VPN, то можете воспользоваться другой LLM на Ваш выбор (можно, например, этим https://ollama.com/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "yeWbkBn5X_xN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ollama OK. Модели: ['llama3.1:latest']\n"
          ]
        }
      ],
      "source": [
        "OLLAMA_HOST = \"http://localhost:11434\"\n",
        "LLAMA_MODEL_NAME = \"llama3.1\"\n",
        "\n",
        "try:\n",
        "    response = requests.get(f\"{OLLAMA_HOST}/api/tags\", timeout=5)\n",
        "    if response.status_code == 200:\n",
        "        models = response.json().get('models', [])\n",
        "        print(f\"Ollama OK. Модели: {[m['name'] for m in models]}\")\n",
        "except Exception as e:\n",
        "    print(f\"Ollama NOT OK: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate(prompt: str) -> str:\n",
        "    response = requests.post(\n",
        "        f\"{OLLAMA_HOST}/api/generate\",\n",
        "        json={\n",
        "            \"model\": LLAMA_MODEL_NAME,\n",
        "            \"prompt\": prompt,\n",
        "            \"stream\": False,\n",
        "            \"options\": {\n",
        "                \"temperature\": 0.7,\n",
        "                \"top_p\": 0.9,\n",
        "                \"max_tokens\": 512\n",
        "            }\n",
        "        },\n",
        "        timeout=30\n",
        "    )\n",
        "        \n",
        "    if response.status_code == 200:\n",
        "        return response.json().get('response', '').strip()\n",
        "    else:\n",
        "        print(f\"api error: {response.status_code}\")\n",
        "        return \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompts = [\n",
        "        \"Напиши 10 коротких предложений (максимум 8 слов) на русском языке с частыми опечатками, которые возникают при распознавании речи. В каждом предложении должно быть 1-2 опечатки. В ответе должны бать только предложения с ошибками. Каждое предложение с новой строки\",\n",
        "        \n",
        "        \"Создай список из 10 коротких фраз (максимум 5 слов) на русском языке с ошибками, похожими на те, что возникают при распознавании speech-to-text. Ошибки должны быть фонетическими. В ответе должны бать только предложения с ошибками. Каждое предложение с новой строки\",\n",
        "        \n",
        "        \"Напиши 10 коротких предложений (максимум 8 слов) на русском языке с опечатками, которые часто встречаются при автоматическом распознавании речи. Включи замены букв, пропуски букв, лишние буквы. В одном предложении может быть 1-2 ошибки. В ответе должны бать только предложения с ошибками. Каждое предложение с новой строки\",\n",
        "        \n",
        "        \"Создай 10 коротких текстов (максимум 8 слов) на русском языке с типичными ошибками распознавания речи: замены похожих звуков, неправильное разделение слов, фонетические искажения. В одном предложении может быть 1-2 ошибки. В ответе должны бать только предложения с ошибками. Каждое предложение с новой строки\",\n",
        "        \n",
        "        \"Напиши 10 коротких фраз (максимум 8 слов) с опечатками, имитирующими ошибки голосового ввода. Ошибки должны быть реалистичными для русского языка. В одном предложении может быть 1-2 ошибки. В ответе должны бать только предложения с ошибками. Каждое предложение с новой строки\",\n",
        "        \n",
        "        \"Создай 10 коротких предложений (максимум 8 слов) с ошибками распознавания речи: замены 'ш' на 'с', 'ч' на 'т', 'в' на 'ф', и другие типичные фонетические замены. В одном предложении может быть 1-2 ошибки. В ответе должны бать только предложения с ошибками. Каждое предложение с новой строки\",\n",
        "        \n",
        "        \"Напиши 10 коротких текстов (максимум 8 слов) с опечатками, характерными для автоматического распознавания русской речи: неправильное ударение, замена согласных, пропуски гласных. В одном предложении может быть 1-2 ошибки. В ответе должны бать только предложения с ошибками. Каждое предложение с новой строки\",\n",
        "        \n",
        "        \"Создай 10 коротких фраз (максимум 8 слов) с ошибками, похожими на те, что возникают при преобразовании речи в текст: замена похожих звуков, неправильное разбиение слов, фонетические искажения. В одном предложении может быть 1-2 ошибки. В ответе должны бать только предложения с ошибками. Каждое предложение с новой строки\",\n",
        "        \n",
        "        \"Напиши 10 коротких предложений (максимум 8 слов) на русском языке с реалистичными опечатками speech-to-text: замены 'и' на 'ы', 'о' на 'а', неправильные окончания слов. В одном предложении может быть 1-2 ошибки. В ответе должны бать только предложения с ошибками. Каждое предложение с новой строки\",\n",
        "        \n",
        "        \"Создай 10 коротких текстов (максимум 8 слов) с типичными ошибками распознавания речи: замена звонких на глухие согласные, неправильное разделение слов, фонетические замены. В одном предложении может быть 1-2 ошибки. В ответе должны бать только предложения с ошибками. Каждое предложение с новой строки\"\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List, Dict\n",
        "\n",
        "def parse_response_text(text: str) -> List[Dict[str, str]]:\n",
        "    pairs = []\n",
        "    lines = text.strip().split('\\n')\n",
        "    \n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if not line or len(line) < 2:\n",
        "            continue\n",
        "            \n",
        "        if line[0].isdigit() and '.' in line[:3]:\n",
        "            line = line.split('.', 1)[1].strip()\n",
        "        \n",
        "        pairs.append({'incorrect': line, 'correct': ''})\n",
        "    \n",
        "    return pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def collect_dataset(num_samples: int = 1200) -> List[Dict[str, str]]:\n",
        "    dataset = []\n",
        "        \n",
        "    for i in range(len(prompts)):\n",
        "        prompt_text = prompts[i]\n",
        "        generated_text = generate(prompt_text)\n",
        "        \n",
        "        if generated_text:\n",
        "            pairs = parse_response_text(generated_text)\n",
        "            \n",
        "            for pair in pairs:\n",
        "                corrected = generate(f\"Исправь опечатки в этом тексте: {pair['incorrect']} В твоем ответе должно быть только предложение, никакого другого текста\")\n",
        "                pair['correct'] = corrected\n",
        "\n",
        "        if len(dataset) >= num_samples:\n",
        "            break\n",
        "    \n",
        "    while len(dataset) < num_samples:\n",
        "        generated = generate(\"Напиши простое короткое предложение (максимум 8 слов) на русском языке с 1-2 опечатками. В предложении может быть 1-2 ошибки. В твоем ответе должно быть только предложение, никакого другого текста\")\n",
        "        \n",
        "        if generated:\n",
        "            corrected = generate(f\"Исправь опечатки: {generated} В твоем ответе должно быть только предложение, никакого другого текста\")\n",
        "            if corrected and generated != corrected:\n",
        "                dataset.append({'incorrect': generated, 'correct': corrected})\n",
        "    \n",
        "    return dataset[:num_samples]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = collect_dataset(1200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collected 1200 \n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nCollected {len(dataset)} \")\n",
        "    \n",
        "df = pd.DataFrame(dataset)\n",
        "df.to_csv('spell_dataset.csv', index=False, encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "df = pd.read_csv('spell_dataset.csv')\n",
        "dataset = Dataset.from_pandas(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import HfApi, login\n",
        "\n",
        "def upload_to_huggingface(dataset, repo_name):\n",
        "    login(token=\"your token\")\n",
        "    dataset.push_to_hub(repo_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "964ed2c8c6a8473786e45bd96670d0bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce1a705a5fcc4b64bd97658372eb1406",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cbb5f86c214b4b49801325699f08276c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3facb29ce2f499cab5d50d82fca84b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload: |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2a5b909358543919336803c7574e2b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Deleting unused files from dataset repository:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "591629fa496f4e95ad90b3d32dc8bafb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/311 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "upload_to_huggingface(dataset, \"lulu-fw01/russian-spell-correction-dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31fdc9c56b8f48b49a43b59c73edddb4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/1200 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset.save_to_disk(\"./spell_correction_dataset_hf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "https://huggingface.co/datasets/lulu-fw01/russian-spell-correction-dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tg9OoCu1iPkG"
      },
      "source": [
        "## Шаг 4 (2 балла)\n",
        "\n",
        "Дообучите модель выше или любую другую модель, которая вам нравится, на собранных данных и протестируйте ее на нескольких ошибочно распознанных whisper-small моделью аудио. Дообучение мы разбирали на семинаре - можете посмотреть, как мы это делали там.\n",
        "\n",
        "Для оценки качества результата выведите на экран 10 текстов с предыдущего шага и их исправления с помощью модели.\n",
        "\n",
        "- Вы можете воспользовать структурой, предложенной в ячейке ниже, а можете написать код по-своему."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "BATCH_SIZE = 8\n",
        "LEARNING_RATE = 5e-5\n",
        "NUM_EPOCHS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ca4417dffbd403291f82a24a16276be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/900 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1a11c8eb91146c197444c551e3cfe3e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='339' max='339' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [339/339 01:36, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "('./spell_correction_finetuned/tokenizer_config.json',\n",
              " './spell_correction_finetuned/special_tokens_map.json',\n",
              " './spell_correction_finetuned/tokenizer.json')"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import (\n",
        "    AutoTokenizer, \n",
        "    AutoModelForSeq2SeqLM, \n",
        "    DataCollatorForSeq2Seq, \n",
        "    Seq2SeqTrainer, \n",
        "    Seq2SeqTrainingArguments\n",
        ")\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(T5_MODEL_NAME)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(T5_MODEL_NAME)\n",
        "\n",
        "df = pd.read_csv('spell_dataset.csv')\n",
        "dataset = Dataset.from_pandas(df)\n",
        "train_size = int(0.75 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset = dataset.select(range(train_size))\n",
        "val_dataset = dataset.select(range(train_size, train_size + val_size))\n",
        "dataset_dict = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'validation': val_dataset\n",
        "})\n",
        "\n",
        "\n",
        "def tokenize_function(texts):\n",
        "    model_inputs = tokenizer(\n",
        "        texts['incorrect'],\n",
        "        max_length=MAX_LENGTH,\n",
        "        truncation=True,\n",
        "        padding=True\n",
        "    )\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(\n",
        "            texts['correct'],\n",
        "            max_length=MAX_LENGTH,\n",
        "            truncation=True,\n",
        "            padding=True\n",
        "        )\n",
        "    \n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "tokenized_datasets = dataset_dict.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=dataset_dict['train'].column_names\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer=tokenizer,\n",
        "    model=model,\n",
        "    padding=True\n",
        ")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./spell_correction_finetuned\",\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=500,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "    report_to=None,\n",
        "    dataloader_pin_memory=False,\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=False,\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "train_result = trainer.train()    \n",
        "trainer.save_model(\"./spell_correction_finetuned\")\n",
        "tokenizer.save_pretrained(\"./spell_correction_finetuned\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "model_path = \"./spell_correction_finetuned\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnPx1UTMf6lQ"
      },
      "source": [
        "Примените дообученную модель. Как раз здесь для оценки качества результата выведите на экран 10 текстов с предыдущего шага и их исправления с помощью модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "-uVrL7hHgr-8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text 1:\n",
            "Original:  Римский каникул\n",
            "Fixed: Римские каникулы.\n",
            "--------------------------------------------------\n",
            "Text 2:\n",
            "Original:  Michael Fradey\n",
            "Fixed: Michael Fradey\n",
            "--------------------------------------------------\n",
            "Text 3:\n",
            "Original:  КОУ ПОРТЕР\n",
            "Fixed: КОМУ ПОРТЕР?\n",
            "--------------------------------------------------\n",
            "Text 4:\n",
            "Original:  Жизнь других.\n",
            "Fixed: Жизнь других.\n",
            "--------------------------------------------------\n",
            "Text 5:\n",
            "Original:  Новый кинотеатр пародизо\n",
            "Fixed: Новый кинотеатр пародии на новый кинотеатр пародии.\n",
            "--------------------------------------------------\n",
            "Text 6:\n",
            "Original:  Аристотель.\n",
            "Fixed: Аристотель.\n",
            "--------------------------------------------------\n",
            "Text 7:\n",
            "Original:  Рене-декарт.\n",
            "Fixed: Рене-де-Карте\n",
            "--------------------------------------------------\n",
            "Text 8:\n",
            "Original:  Смоки Робинсон\n",
            "Fixed: Смоки Робинсон\n",
            "--------------------------------------------------\n",
            "Text 9:\n",
            "Original:  Мой сосед татура.\n",
            "Fixed: Мой сосед Татура.\n",
            "--------------------------------------------------\n",
            "Text 10:\n",
            "Original:  Бабель Исаак, Эммануи Лавич.\n",
            "Fixed: Бабель Исаак Исаак и Эммануэль Лавич.\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for i, original_text in enumerate(texts[:10], 1):\n",
        "    print(f\"Text {i}:\")\n",
        "    print(f\"Original: {original_text}\")    \n",
        "    corrected = correct_text(model, tokenizer, original_text) \n",
        "    print(f\"Fixed: {corrected}\")\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tnKOwwAjNsF"
      },
      "source": [
        "## Шаг 5 (1 балл)\n",
        "\n",
        "Время считать метрики и возвращаться к дообучению модели по необходимости. В этом шаге мы оцениваем только выполнение задания, а не значения метрик.\n",
        "\n",
        "a) [Здесь](https://disk.yandex.ru/d/SPJU3lCt_cMDcw) лежат правильные ответы почти на все аудио - считайте метрики только для аудио, для которых мы дали вам ответы. Посчитайте [WER](https://docs.pytorch.org/torcheval/main/generated/torcheval.metrics.WordErrorRate.html) для модели whisper-small.\n",
        "\n",
        "б) Посчитайте WER для whisper-small + исправление опечаток предобученной моделью (модель выберите самостоятельно!)\n",
        "\n",
        "в) Посчитайте WER для whisper-small + дообученная Вами модель (данные для дообучения и модель выберите самостоятельно!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "8Ik_jNo2jNzC"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from torcheval.metrics import WordErrorRate\n",
        "\n",
        "\n",
        "with open('result_array.json', 'r', encoding='utf-8') as f:\n",
        "    correct_data = json.load(f)\n",
        "\n",
        "model_path = \"./spell_correction_finetuned\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
        "processor = WhisperProcessor.from_pretrained(WHISPER_MODEL_NAME)\n",
        "model_whisper = WhisperForConditionalGeneration.from_pretrained(WHISPER_MODEL_NAME)  \n",
        "\n",
        "sample_size = min(20, len(correct_data))\n",
        "sample_data = correct_data[:sample_size]\n",
        "\n",
        "whisper_texts = []\n",
        "corrected_texts = []\n",
        "correct_texts = []\n",
        "\n",
        "wer_whisper = WordErrorRate()\n",
        "wer_corrected = WordErrorRate()\n",
        "\n",
        "for i, item in enumerate(sample_data):\n",
        "    url = item['url']\n",
        "    correct_text_ref = item['text']\n",
        "    whisper_text = recognize_audio(processor, model_whisper, url).lower()\n",
        "    corrected_text = correct_text(model, tokenizer, whisper_text).lower()\n",
        "    \n",
        "    whisper_texts.append(whisper_text)\n",
        "    corrected_texts.append(corrected_text)\n",
        "    correct_texts.append(correct_text_ref)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torcheval\n",
            "  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: typing-extensions in /Users/lumarkov/git/luka/GM-HSE-AI-masters-course/ml_env_py311/lib/python3.11/site-packages (from torcheval) (4.15.0)\n",
            "Downloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n",
            "Installing collected packages: torcheval\n",
            "Successfully installed torcheval-0.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install torcheval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "WER Whisper: 0.700\n",
            "WER после исправления дообученной моделью: 0.900\n"
          ]
        }
      ],
      "source": [
        "\n",
        "wer_whisper.update(whisper_texts, correct_texts)\n",
        "wer_corrected.update(corrected_texts, correct_texts)\n",
        "\n",
        "whisper_wer = wer_whisper.compute().item()\n",
        "corrected_wer = wer_corrected.compute().item()\n",
        "print(f\"\\nWER Whisper: {whisper_wer:.3f}\")\n",
        "print(f\"WER после исправления дообученной моделью: {corrected_wer:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "пу пу пу"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sUQNgLjj4lQ"
      },
      "source": [
        "## Шаг 6 (3 балла)\n",
        "\n",
        "В этом шаге предлагаем вам провести максимум рисерча и экспериментов для наиболее качественного решения задачи (в бесплатном google colab, без привлечения дополнительных мощностей)\n",
        "\n",
        "* Поищите предобученные модели, применение которых для задачи speech-to-text дает меньше опечаток (меньше WER)\n",
        "\n",
        "* Протестируйте несколько spell-correction моделей и сделайте выводы какая из них лучше (с точки зрения WER)\n",
        "\n",
        "* Возьмите лучшую из найденных моделей и попытайтесь улучшить ее через шаг 4, как делали ранее. Попробуйте немного изменить обучение в шаге 4, чтобы добиться еще более хороших результатов (изменить данные/гиперпараметры и т.п.) и проведите соответствующий эксперимент. Объясните почему ваша модификация шага 4 теоретически может улучшить результаты и сделайте выводы о том, получилось ли улучшить качество (если нет, то предположите почему)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1oi72ysj9ao"
      },
      "outputs": [],
      "source": [
        "# ваши эксперименты здесь"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNA0WBwajj0aat4A693n8Zo",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml_env_py311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
